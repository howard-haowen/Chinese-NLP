{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chinese-tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUgBqJTBP9NdTJDjq2BZz3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/howard-haowen/NLP-demos/blob/main/Chinese_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY33qWpyS3HQ"
      },
      "outputs": [],
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download zh_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "c0-QmDvkTF4l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -l -s https://github.com/L706077/jieba-zh_TW.git jieba_tw\n",
        "%cd jieba_tw\n",
        "import jieba\n",
        "%cd ../"
      ],
      "metadata": {
        "id": "PiAIHBhpTGeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Doc\n",
        "\n",
        "nlp = spacy.load(\"zh_core_web_sm\")\n",
        "\n",
        "class TwTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words =  jieba.lcut(text)\n",
        "        spaces = [False] * len(words)        \n",
        "        return Doc(self.vocab, words=words, spaces=spaces)\n",
        "\n",
        "nlp.tokenizer = TwTokenizer(nlp.vocab)"
      ],
      "metadata": {
        "id": "FIRoUtq3TQeP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"宜家家居新店店店長的名字好長喔！\"\n",
        "doc = nlp(text)\n",
        "tokens = [tok.text for tok in doc]\n",
        "\" | \".join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "PcasPr8FTaSG",
        "outputId": "785c1d9f-e8b9-493b-aaa5-806ae133c29a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.159 seconds.\n",
            "Prefix dict has been built succesfully.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'宜家 | 家居 | 新店店 | 店長 | 的 | 名字 | 好長 | 喔 | ！'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text: str) -> list:\n",
        "    doc = nlp.make_doc(text)\n",
        "    res = [tok for tok in doc if not tok.is_punct]\n",
        "    res = [tok for tok in res if not tok.is_stop] # stop words\n",
        "    res = [tok for tok in res if not tok.like_email]\n",
        "    res = [tok for tok in res if not tok.like_url]\n",
        "    res = [tok for tok in res if not tok.like_num]\n",
        "    res = [tok for tok in res if not tok.is_ascii]\n",
        "    res = [tok.text for tok in res if not tok.is_space]\n",
        "    return res"
      ],
      "metadata": {
        "id": "Px1Rvy54UCMM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "（中央社）迎接虎年到來，台北101今天表示，即日起推出「虎年新春燈光秀」，將持續至2月5日，每晚6時至10時，除整點會有報時燈光變化外，每15分鐘還會有3分鐘的燈光秀。台北101下午透過新聞稿表示，今年特別設計「虎年新春燈光秀」，從今晚開始閃耀台北天際線，一直延續至2月5日，共7天。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FitSfOxXUDeX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toks = preprocess_text(text)\n",
        "print(toks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmjULmqHUdRF",
        "outputId": "6ba577d4-b041-458e-bc6a-f8a259141e90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['中央社', '迎接', '虎年', '到來', '台北', '即日', '推出', '虎年', '新春', '燈光秀', '將', '持續', '月', '日', '每晚', '時', '時', '除整', '點會', '報時', '燈光', '變化', '外', '分鐘', '還', '會', '分鐘', '燈光秀', '台北', '下午', '透過', '新聞稿', '特別', '設計', '虎年', '新春', '燈光秀', '從', '今晚', '開始', '閃耀', '台北', '天際線', '延續', '月', '日', '天']\n"
          ]
        }
      ]
    }
  ]
}